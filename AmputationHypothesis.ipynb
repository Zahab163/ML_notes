{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/0EK4OBxzcfIwuE8EuTE1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zahab163/ML_notes/blob/main/AmputationHypothesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ What Is Simple Amputation in Stats & Python?\n",
        "\n",
        "In **statistics and data science**, **amputation** refers to the **intentional removal or masking of data**‚Äîoften used to simulate **missing data** for testing imputation methods.\n",
        "\n",
        "### üîç Simple Amputation\n",
        "**Simple amputation** means:\n",
        "- Randomly removing values from a dataset\n",
        "- Typically done **uniformly** across variables or rows\n",
        "- Used to **test imputation techniques** like mean imputation, KNN, or MICE\n",
        "\n",
        "---\n",
        "\n",
        "## üêç Python Example: Simulating Missing Data\n",
        "\n",
        "Here‚Äôs how you might perform simple amputation using Python:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample dataset\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'age': np.random.randint(20, 60, size=10),\n",
        "    'income': np.random.randint(30000, 100000, size=10)\n",
        "})\n",
        "\n",
        "# Simple amputation: randomly remove 30% of values in 'income'\n",
        "mask = np.random.rand(len(data)) < 0.3\n",
        "data.loc[mask, 'income'] = np.nan\n",
        "\n",
        "print(data)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Why Use Amputation?\n",
        "- To **benchmark imputation algorithms**\n",
        "- To **simulate real-world missingness**\n",
        "- To understand how models behave with **incomplete data**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "BmEkcpkRWPiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's amputation using python"
      ],
      "metadata": {
        "id": "vRm-ysS9lhGr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzwyxCHCuzEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da2a327-187d-41b5-87fb-2e3eac7d65f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age   income\n",
            "0   58      NaN\n",
            "1   48      NaN\n",
            "2   34      NaN\n",
            "3   27  71090.0\n",
            "4   40  97221.0\n",
            "5   58  94820.0\n",
            "6   38      NaN\n",
            "7   42  89735.0\n",
            "8   30      NaN\n",
            "9   30      NaN\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample dataset\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'age': np.random.randint(20, 60, size=10),\n",
        "    'income': np.random.randint(30000, 100000, size=10)\n",
        "})\n",
        "\n",
        "# Simple amputation: randomly remove 30% of values in 'income'\n",
        "mask = np.random.rand(len(data)) < 0.3\n",
        "data.loc[mask, 'income'] = np.nan\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Here‚Äôs how you might simulate MCAR amputation:\n",
        "\n"
      ],
      "metadata": {
        "id": "KKcBjWwNmcha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "df = pd.DataFrame({\n",
        "    'age': np.random.randint(20, 60, 100),\n",
        "    'income': np.random.randint(30000, 100000, 100)\n",
        "})\n",
        "\n",
        "# MCAR: Randomly remove 20% of income values\n",
        "mask = np.random.rand(len(df)) < 0.2\n",
        "df.loc[mask, 'income'] = np.nan"
      ],
      "metadata": {
        "id": "JhkR0o2JmmBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For MAR, you‚Äôd condition missingness on another variable:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YJLHHL_Dmsqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MAR: Remove income if age < 30\n",
        "df.loc[df['age'] < 30, 'income'] = np.nan"
      ],
      "metadata": {
        "id": "i7fNShlXm6Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What Is the Interquartile Range (IQR)?\n",
        "The interquartile range (IQR) is a measure of statistical dispersion that describes the spread of the middle 50% of a dataset. It‚Äôs calculated as:\n",
        "\\text{IQR} = Q3 - Q1\n",
        "- Q1 (First Quartile): The 25th percentile ‚Äî the value below which 25% of the data falls\n",
        "- Q3 (Third Quartile): The 75th percentile ‚Äî the value below which 75% of the data falls\n",
        "- So, IQR captures the range between the 25th and 75th percentiles\n",
        "\n",
        "üß† Why Use IQR?\n",
        "- Robust to outliers: Unlike the full range, IQR isn‚Äôt affected by extreme values\n",
        "- Useful for skewed data: Works well when data isn‚Äôt normally distributed\n",
        "- Helps detect outliers: Values outside Q1 - 1.5 \\times IQR or Q3 + 1.5 \\times IQR are often considered outliers\n"
      ],
      "metadata": {
        "id": "x08mAX2Toxbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = [12, 15, 14, 10, 18, 21, 24, 30, 35, 40]\n",
        "\n",
        "# Convert to Series\n",
        "series = pd.Series(data)\n",
        "\n",
        "# Calculate IQR\n",
        "Q1 = series.quantile(0.25)\n",
        "Q3 = series.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "print(f\"Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lwGjL6Eoyil",
        "outputId": "045529ad-6c78-4bb8-da09-53778fed7af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: 14.25, Q3: 28.5, IQR: 14.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In **data science and statistics**, the method to **perform amputation**‚Äîi.e., simulate missing data‚Äîis crucial for evaluating how well imputation techniques work. Here's how it's typically done:\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Methods to Perform Amputation in Data\n",
        "\n",
        "### 1. **Manual Amputation (Basic Python)**\n",
        "You can manually remove values using conditions or random masking:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "df = pd.DataFrame({\n",
        "    'age': np.random.randint(20, 60, 100),\n",
        "    'income': np.random.randint(30000, 100000, 100)\n",
        "})\n",
        "\n",
        "# MCAR: Randomly remove 20% of income values\n",
        "mask = np.random.rand(len(df)) < 0.2\n",
        "df.loc[mask, 'income'] = np.nan\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Multivariate Amputation (Advanced Simulation)**\n",
        "\n",
        "For more realistic missingness (MAR, MNAR), use specialized tools like:\n",
        "\n",
        "#### üîß `pyampute` (Python Library)\n",
        "- Simulates missing data with control over mechanism (MCAR, MAR, MNAR)\n",
        "- Compatible with scikit-learn pipelines\n",
        "- Example usage:\n",
        "\n",
        "```python\n",
        "from pyampute.ampute import MultivariateAmputation\n",
        "import numpy as np\n",
        "\n",
        "# Create complete dataset\n",
        "X_complete = np.random.randn(1000, 10)\n",
        "\n",
        "# Apply amputation\n",
        "ma = MultivariateAmputation()\n",
        "X_incomplete = ma.fit_transform(X_complete)\n",
        "```\n",
        "\n",
        "üìå Learn more on [GitHub - pyampute](https://github.com/RianneSchouten/pyampute)\n",
        "\n",
        "---\n",
        "\n",
        "#### üß† `ampute` in R (`mice` package)\n",
        "- Offers fine-grained control over missingness patterns\n",
        "- Supports mixed mechanisms and complex designs\n",
        "- Tutorial: [Generate missing values with ampute](https://rianneschouten.github.io/mice_ampute/vignette/ampute.html)\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ Use Cases\n",
        "- Benchmarking imputation methods (mean, KNN, MICE)\n",
        "- Simulating real-world data collection issues\n",
        "- Teaching and research in missing data methodology\n",
        "\n"
      ],
      "metadata": {
        "id": "9tpuRPq6VB6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visual Insight: Box Plot\n",
        "The IQR is the length of the box in a box plot. It shows where the bulk of your data lies and helps visualize skewness and outliers.\n"
      ],
      "metadata": {
        "id": "C_ice3OFpCq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methods to Perform Amputation in Data\n",
        "1. Manual Amputation (Basic Python)\n",
        "You can manually remove values using conditions or random masking:\n"
      ],
      "metadata": {
        "id": "2Mi88nDtsZdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "df = pd.DataFrame({\n",
        "    'age': np.random.randint(20, 60, 100),\n",
        "    'income': np.random.randint(30000, 100000, 100)\n",
        "})\n",
        "\n",
        "# MCAR: Randomly remove 20% of income values\n",
        "mask = np.random.rand(len(df)) < 0.2\n",
        "df.loc[mask, 'income'] = np.nan"
      ],
      "metadata": {
        "id": "no3JAktesdPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Multivariate Amputation (Advanced Simulation)\n",
        "For more realistic missingness (MAR, MNAR), use specialized tools like:\n",
        "üîß pyampute (Python Library)\n",
        "- Simulates missing data with control over mechanism (MCAR, MAR, MNAR)\n",
        "- Compatible with scikit-learn pipelines\n",
        "- Example usage:\n"
      ],
      "metadata": {
        "id": "6wLpRhdts0SF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11ce4f99",
        "outputId": "43f58561-5287-4b53-fef6-97e5db5cf741"
      },
      "source": [
        "%pip install pyampute"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyampute\n",
            "  Downloading pyampute-0.0.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pyampute) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from pyampute) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyampute) (1.16.1)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyampute) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pyampute) (1.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.4.0->pyampute) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.4.0->pyampute) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.4.0->pyampute) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.4.0->pyampute) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.4.0->pyampute) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.4.0->pyampute) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.4.0->pyampute) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.4.0->pyampute) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pyampute) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pyampute) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyampute) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyampute) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->pyampute) (1.17.0)\n",
            "Downloading pyampute-0.0.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: pyampute\n",
            "Successfully installed pyampute-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scripts/generate_shift_lookup_table.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Create score range\n",
        "scores = np.linspace(0, 1, 101)\n",
        "# Example: probability = score squared\n",
        "probabilities = scores ** 2\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({'score': scores, 'probability': probabilities})\n",
        "\n",
        "# Ensure data folder exists\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('data/shift_lookup.csv', index=False)\n",
        "print(\"Lookup table generated at data/shift_lookup.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39h3kEi1uyn3",
        "outputId": "f14a9488-648a-42e7-b822-487e2d84c94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lookup table generated at data/shift_lookup.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#If you're using this in a Streamlit app or ML pipeline, consider adding a check like:\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"data/shift_lookup.csv\"):\n",
        "    print(\"Lookup table missing. Please run generate_shift_lookup_table.py.\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BClTOKMUuHlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the row where the 'score' is 0.50 using boolean indexing\n",
        "prob = df.loc[df['score'] == 0.50]"
      ],
      "metadata": {
        "id": "tpwsibDTwDxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = 0.50\n",
        "closest_score = df_lookup.index[df_lookup.index.to_series().sub(score).abs().idxmin()]\n",
        "prob = df_lookup.loc[closest_score]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "UXk603PkwjZe",
        "outputId": "5a7d1429-62c3-4f66-9bd8-c29a94298629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_lookup' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3937516478.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclosest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclosest_score\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_lookup' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = 0.50\n",
        "match = df_lookup[np.isclose(df_lookup.index, score)]\n",
        "if not match.empty:\n",
        "    prob = match.iloc[0]\n",
        "else:\n",
        "    print(\"Score not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "PwFMQ5j2woiE",
        "outputId": "43339524-b708-4f76-981d-36269ab41c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_lookup' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-382386506.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_lookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_lookup' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_lookup[df_lookup['score'] == 0.50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "9bAsdQwvw3u8",
        "outputId": "d7341143-95ed-48fd-d8c7-0fb19c6380ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_lookup' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4167244971.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_lookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_lookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_lookup' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyampute.ampute import MultivariateAmputation\n",
        "import numpy as np\n",
        "\n",
        "# Create complete dataset\n",
        "X_complete = np.random.randn(1000, 10)\n",
        "\n",
        "# Apply amputation\n",
        "# Pass the missingness proportion as an integer percentage (e.g., 50 for 50%)\n",
        "ma = MultivariateAmputation(prop=50)\n",
        "X_incomplete = ma.fit_transform(X_complete)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "apWkYXE8s7_Z",
        "outputId": "9f56fd59-42ed-43d7-8618-59fbf7866b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'0.50'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '0.50'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3439411762.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Pass the missingness proportion as an integer percentage (e.g., 50 for 50%)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultivariateAmputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_incomplete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_complete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyampute/ampute.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_sumscores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0;31m# define candidate probabilities in group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_choose_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m             \u001b[0;31m# apply probabilities and choose cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;31m# set seed for random binomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyampute/ampute.py\u001b[0m in \u001b[0;36m_choose_probabilities\u001b[0;34m(self, pattern_index)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mwss_standardized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# calculate the size of b for the desired missingness proportion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             probs_array = self._calculate_probabilities_from_wss(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mwss_standardized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_to_probability_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpattern_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyampute/ampute.py\u001b[0m in \u001b[0;36m_calculate_probabilities_from_wss\u001b[0;34m(self, wss_standardized, score_to_probability_func, missingness_percent, lower_range, upper_range, max_iter, max_diff_with_target)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 shift = self.shift_lookup_table.loc[\n\u001b[0m\u001b[1;32m    312\u001b[0m                     \u001b[0mscore_to_probability_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4214\u001b[0;31m         \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4215\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4636\u001b[0m             \u001b[0;31m#  pending resolution of GH#33047\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4638\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4639\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '0.50'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scripts/generate_shift_lookup_table.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "N4bASXuZuX0l",
        "outputId": "a9ae50cc-cc1c-46ef-ecf1-53045ab67054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'scripts' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3261635298.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscripts\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgenerate_shift_lookup_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'scripts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In data science and statistics, the method to perform amputation‚Äîi.e., simulate missing data‚Äîis crucial for evaluating how well imputation techniques work. Here's how it's typically done:\n",
        "\n",
        "üß™ Methods to Perform Amputation in Data\n",
        "1. Manual Amputation (Basic Python)\n",
        "You can manually remove values using conditions or random masking:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "df = pd.DataFrame({\n",
        "    'age': np.random.randint(20, 60, 100),\n",
        "    'income': np.random.randint(30000, 100000, 100)\n",
        "})\n",
        "\n",
        "# MCAR: Randomly remove 20% of income values\n",
        "mask = np.random.rand(len(df)) < 0.2\n",
        "df.loc[mask, 'income'] = np.nan\n",
        "\n",
        "\n",
        "\n",
        "2. Multivariate Amputation (Advanced Simulation)\n",
        "For more realistic missingness (MAR, MNAR), use specialized tools like:\n",
        "üîß pyampute (Python Library)\n",
        "- Simulates missing data with control over mechanism (MCAR, MAR, MNAR)\n",
        "- Compatible with scikit-learn pipelines\n",
        "- Example usage:\n",
        "from pyampute.ampute import MultivariateAmputation\n",
        "import numpy as np\n",
        "\n",
        "# Create complete dataset\n",
        "X_complete = np.random.randn(1000, 10)\n",
        "\n",
        "# Apply amputation\n",
        "ma = MultivariateAmputation()\n",
        "X_incomplete = ma.fit_transform(X_complete)\n",
        "\n",
        "\n",
        "üìå Learn more on GitHub - pyampute\n",
        "\n",
        "üß† ampute in R (mice package)\n",
        "- Offers fine-grained control over missingness patterns\n",
        "- Supports mixed mechanisms and complex designs\n",
        "- Tutorial: Generate missing values with ampute\n",
        "\n",
        "üß≠ Use Cases\n",
        "- Benchmarking imputation methods (mean, KNN, MICE)\n",
        "- Simulating real-world data collection issues\n",
        "- Teaching and research in missing data methodology\n"
      ],
      "metadata": {
        "id": "b0sUvKTetnQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"k-nearest neighbors\" (KNN) in machine learning:\n",
        "That‚Äôs a classification algorithm used to predict the label of a data point based on the labels of its nearest neighbors.\n",
        "KNN is a simple, yet powerful supervised learning algorithm used for classification and regression. It makes predictions based on the ‚Äúk‚Äù closest data points in the training set.\n",
        "üß† Core Idea:\n",
        "‚ÄúBirds of a feather flock together.‚Äù\n",
        "If most of your neighbors are cats, you‚Äôre probably a cat too.\n",
        "\n",
        "\n",
        "# How It Works (Step-by-Step)\n",
        "- Choose a value for k (e.g., 3 or 5)\n",
        "- Calculate the distance between the new data point and all training points (usually Euclidean distance)\n",
        "- Identify the k nearest neighbors\n",
        "- Vote (for classification) or average (for regression)\n",
        "- Assign the label or value\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OZ8R8doz3LFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmZTWVT44YSE",
        "outputId": "48ecb3dd-e5c6-47eb-ed76-f48b5de0b9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ Tips for Choosing ‚Äúk‚Äù\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Value         |     Behavior       |\n",
        "*    Small        | More sensitive to noise |\n",
        "*  Large          | Smoother decision boundary\n",
        "*  Odd            | Helps avoid ties in classification |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Try plotting accuracy vs. k to find the sweet spot!"
      ],
      "metadata": {
        "id": "piHvzN0R4pN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß† What Is KNN?\n",
        "\n",
        "**K-Nearest Neighbors (KNN)** is a **non-parametric, supervised learning algorithm** used for both **classification** and **regression**. It makes predictions based on the **‚Äúcloseness‚Äù of data points** in feature space.\n",
        "\n",
        "> üí° It‚Äôs called a ‚Äúlazy learner‚Äù because it doesn‚Äôt learn a model during training ‚Äî it memorizes the data and makes decisions at prediction time.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç How It Works\n",
        "\n",
        "1. Choose the number of neighbors **k**\n",
        "2. Calculate the **distance** (e.g., Euclidean) between the query point and all training points\n",
        "3. Select the **k closest** points\n",
        "4. For classification: use **majority vote**\n",
        "   For regression: use **average value**\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Python Example: Classification\n",
        "\n",
        "```python\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öñÔ∏è Choosing the Right k\n",
        "\n",
        "- **Small k** ‚Üí sensitive to noise (overfitting)\n",
        "- **Large k** ‚Üí smoother decision boundary (underfitting)\n",
        "- Use **cross-validation** to find the optimal k\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Pros and Cons\n",
        "\n",
        "| Pros                         | Cons                                      |\n",
        "|------------------------------|-------------------------------------------|\n",
        "| Simple and intuitive         | Slow with large datasets                  |\n",
        "| No training phase            | Sensitive to irrelevant features          |\n",
        "| Works well with small data   | Requires feature scaling for accuracy     |\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Learn More\n",
        "\n",
        "- [GeeksforGeeks: KNN Algorithm](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/)\n",
        "- [IBM: What is KNN?](https://www.ibm.com/think/topics/knn)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FIhJiYEdMbG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here‚Äôs a clear breakdown of **stationary vs non-stationary** concepts ‚Äî especially useful for time series analysis and signal processing:\n",
        "\n",
        "---\n",
        "\n",
        "## üìà Stationary vs Non-Stationary Time Series\n",
        "\n",
        "| Feature               | **Stationary**                                      | **Non-Stationary**                                      |\n",
        "|-----------------------|-----------------------------------------------------|----------------------------------------------------------|\n",
        "| **Mean**              | Constant over time                                  | Changes over time                                       |\n",
        "| **Variance**          | Constant over time                                  | Varies with time                                        |\n",
        "| **Autocovariance**    | Depends only on lag, not time                       | Depends on both lag and time                            |\n",
        "| **Trend/Seasonality** | Absent                                              | Present (e.g., upward trend, seasonal spikes)           |\n",
        "| **Forecasting**       | Easier and more reliable                            | Requires transformation (e.g., differencing)            |\n",
        "\n",
        "> A stationary time series always returns to its long-run mean and has consistent statistical properties. Non-stationary series evolve over time ‚Äî think of stock prices or temperature trends.\n",
        "\n",
        "---\n",
        "\n",
        "## üîä Stationary vs Non-Stationary Signals\n",
        "\n",
        "| Feature               | **Stationary Signals**                              | **Non-Stationary Signals**                              |\n",
        "|-----------------------|-----------------------------------------------------|----------------------------------------------------------|\n",
        "| **Frequency**         | Constant                                             | Varies over time                                        |\n",
        "| **Spectral Content**  | Fixed                                                | Dynamic                                                 |\n",
        "| **Examples**          | Sine wave with fixed frequency                      | Speech, music, real-world signals                       |\n",
        "| **Analysis Method**   | Fourier Transform works well                        | Requires advanced methods (e.g., Wavelet Transform)     |\n",
        "\n",
        "> Stationary signals are predictable and easier to analyze. Non-stationary signals, like speech or ECG data, change with time and need more sophisticated tools.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ How to Test for Stationarity\n",
        "\n",
        "- **Visual Inspection**: Look for trends or seasonality in plots  \n",
        "- **Statistical Tests**:\n",
        "  - Augmented Dickey-Fuller (ADF) test  \n",
        "  - KPSS test  \n",
        "  - Run sequence plots  \n",
        "  - Wavelet-based tests\n",
        "\n",
        "---\n",
        "\n",
        "## üîÑ Making Data Stationary\n",
        "\n",
        "If your data is non-stationary, you can:\n",
        "- **Difference the series** (subtract previous value from current)\n",
        "- **Remove trends** (e.g., linear detrending)\n",
        "- **Log transform** or **seasonal adjustment**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kYkQuLY7U_-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß† What Is Hypothesis Testing?\n",
        "\n",
        "**Hypothesis testing** is a statistical method used to evaluate assumptions about a population based on sample data. It helps determine whether a claim (the hypothesis) is likely true or should be rejected.\n",
        "\n",
        "> Think of it as a structured way to ask: ‚ÄúIs this result real, or just random chance?‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Key Components\n",
        "\n",
        "| Term                  | Meaning                                                                 |\n",
        "|-----------------------|-------------------------------------------------------------------------|\n",
        "| **Null Hypothesis (H‚ÇÄ)**     | Assumes no effect or no difference (e.g., ‚ÄúThe mean = 50‚Äù)             |\n",
        "| **Alternative Hypothesis (H‚ÇÅ or Ha)** | Suggests a real effect or difference (e.g., ‚ÄúThe mean ‚â† 50‚Äù)            |\n",
        "| **Significance Level (Œ±)**   | Probability of rejecting H‚ÇÄ when it‚Äôs actually true (commonly 0.05)     |\n",
        "| **p-value**           | Probability of observing the data if H‚ÇÄ is true                          |\n",
        "| **Test Statistic**    | A value (e.g., Z, t, œá¬≤) used to decide whether to reject H‚ÇÄ             |\n",
        "| **Critical Value**    | Threshold beyond which H‚ÇÄ is rejected                                   |\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Steps in Hypothesis Testing\n",
        "\n",
        "1. **State the hypotheses**: Define H‚ÇÄ and H‚ÇÅ  \n",
        "2. **Choose significance level (Œ±)**: Often 0.05  \n",
        "3. **Collect and analyze data**  \n",
        "4. **Calculate test statistic and p-value**  \n",
        "5. **Make a decision**:  \n",
        "   - If p-value < Œ± ‚Üí Reject H‚ÇÄ  \n",
        "   - If p-value ‚â• Œ± ‚Üí Fail to reject H‚ÇÄ\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Types of Tests\n",
        "\n",
        "| Test Type         | Use Case Example                                      |\n",
        "|-------------------|-------------------------------------------------------|\n",
        "| **Z-test**        | Large samples, known population variance              |\n",
        "| **T-test**        | Small samples, unknown population variance            |\n",
        "| **Chi-square test** | Categorical data, independence or goodness-of-fit     |\n",
        "| **ANOVA**         | Comparing means across 3+ groups                      |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö†Ô∏è Errors in Hypothesis Testing\n",
        "\n",
        "| Error Type        | Description                                           |\n",
        "|-------------------|-------------------------------------------------------|\n",
        "| **Type I Error (Œ±)** | Rejecting H‚ÇÄ when it‚Äôs actually true (false positive) |\n",
        "| **Type II Error (Œ≤)** | Failing to reject H‚ÇÄ when it‚Äôs false (false negative) |\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Want to Learn More?\n",
        "\n",
        "- [Statistics by Jim: Hypothesis Testing Guide](https://statisticsbyjim.com/hypothesis-testing/hypothesis-testing/)  \n",
        "- [GeeksforGeeks: Hypothesis Testing Explained](https://www.geeksforgeeks.org/software-testing/understanding-hypothesis-testing/)  \n",
        "- [Scribbr: Step-by-Step Hypothesis Testing](https://www.scribbr.com/statistics/hypothesis-testing/)\n",
        "\n"
      ],
      "metadata": {
        "id": "FLrg0jkJUJ5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## üìä What Is Z Testing?\n",
        "\n",
        "**Z-test** is a statistical method used to determine whether there's a significant difference between sample and population means, or between two sample means, assuming the population variance is known.\n",
        "\n",
        "It‚Äôs based on the **standard normal distribution** and is most reliable when:\n",
        "- Sample size is **large** (typically **n > 30**)\n",
        "- Population **standard deviation (œÉ)** is known\n",
        "- Data is **normally distributed**\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ Z-Test Formula\n",
        "\n",
        "For a one-sample Z-test:\n",
        "\n",
        "\\[\n",
        "Z = \\frac{\\bar{x} - \\mu}{\\sigma / \\sqrt{n}}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( \\bar{x} \\) = sample mean  \n",
        "- \\( \\mu \\) = population mean  \n",
        "- \\( \\sigma \\) = population standard deviation  \n",
        "- \\( n \\) = sample size\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Types of Z Tests\n",
        "\n",
        "| Type               | Purpose                                                                 |\n",
        "|--------------------|-------------------------------------------------------------------------|\n",
        "| **One-sample Z-test** | Compare sample mean to known population mean                          |\n",
        "| **Two-sample Z-test** | Compare means of two independent samples                              |\n",
        "| **Proportion Z-test** | Compare sample proportion to population proportion or between samples |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Example\n",
        "\n",
        "Suppose the average battery life of a phone is claimed to be 12 hours. You test 100 phones and find the average is 11.8 hours with a known œÉ = 0.5.\n",
        "\n",
        "\\[\n",
        "Z = \\frac{11.8 - 12}{0.5 / \\sqrt{100}} = \\frac{-0.2}{0.05} = -4\n",
        "\\]\n",
        "\n",
        "A Z-score of -4 indicates the sample mean is significantly lower than the population mean.\n",
        "\n",
        "---\n",
        "\n",
        "## üÜö Z-Test vs T-Test\n",
        "\n",
        "| Feature               | **Z-Test**                          | **T-Test**                          |\n",
        "|-----------------------|-------------------------------------|-------------------------------------|\n",
        "| Sample Size           | Large (n > 30)                      | Small (n < 30)                      |\n",
        "| Standard Deviation    | Known (population œÉ)                | Unknown (sample s)                  |\n",
        "| Distribution          | Normal                              | Normal or approximately normal      |\n",
        "\n",
        "---\n",
        "\n",
        "For more details and examples, check out [GeeksforGeeks' Z-Test Guide](https://www.geeksforgeeks.org/dsa/z-test/) or [Statistics by Jim](https://statisticsbyjim.com/hypothesis-testing/z-test/).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PsFltVTGTpd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß† What Is a T-Test?\n",
        "\n",
        "A **T-test** is a statistical method used to determine whether the **means of two groups** are significantly different from each other. It‚Äôs commonly used in **hypothesis testing** to assess the effect of a treatment, intervention, or condition.\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Types of T-Tests\n",
        "\n",
        "| Type                  | Use Case Example                                      |\n",
        "|-----------------------|-------------------------------------------------------|\n",
        "| **One-Sample T-Test** | Compare sample mean to a known value (e.g., claimed average) |\n",
        "| **Two-Sample T-Test** | Compare means of two independent groups (e.g., Method A vs Method B) |\n",
        "| **Paired T-Test**     | Compare means of the same group before and after treatment |\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Python Example: One-Sample T-Test\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Sample data\n",
        "sample = [43, 45, 47, 44, 46, 42, 41, 48, 49, 45]\n",
        "population_mean = 45\n",
        "\n",
        "# Perform one-sample t-test\n",
        "t_stat, p_value = stats.ttest_1samp(sample, population_mean)\n",
        "\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Significant difference. Reject H‚ÇÄ.\")\n",
        "else:\n",
        "    print(\"No significant difference. Fail to reject H‚ÇÄ.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìò Assumptions of T-Test\n",
        "\n",
        "- Data is **normally distributed**\n",
        "- Observations are **independent**\n",
        "- Variances are **equal** (for two-sample tests)\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Interpretation\n",
        "\n",
        "- **T-statistic**: Measures how far the sample mean is from the population mean\n",
        "- **P-value**: Probability of observing the data if the null hypothesis is true\n",
        "- If **p < 0.05**, the result is statistically significant\n",
        "\n",
        "---\n",
        "\n",
        "For a deeper dive, check out:\n",
        "- [Statistics How To ‚Äì T-Test Guide](https://www.statisticshowto.com/probability-and-statistics/t-test/)\n",
        "- [Statistics by Jim ‚Äì T-Test Overview](https://statisticsbyjim.com/hypothesis-testing/t-test/)\n",
        "\n"
      ],
      "metadata": {
        "id": "7uzqbsz4So88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here‚Äôs a clear and practical explanation of **Chi-Square (œá¬≤) Testing** in statistics and Python\n",
        "---\n",
        "\n",
        "## üß† What Is Chi-Square Testing?\n",
        "\n",
        "**Chi-Square tests** are used to determine whether there‚Äôs a **significant difference between observed and expected frequencies** in categorical data.\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Types of Chi-Square Tests\n",
        "\n",
        "| Test Type                        | Purpose                                                                 |\n",
        "|----------------------------------|-------------------------------------------------------------------------|\n",
        "| **Goodness of Fit Test**         | Tests if a single categorical variable follows a specified distribution |\n",
        "| **Test of Independence**         | Tests if two categorical variables are associated                       |\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Python Example: Test of Independence\n",
        "\n",
        "Let‚Äôs say you want to test whether **gender** and **voting preference** are related:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample contingency table\n",
        "data = pd.DataFrame({\n",
        "    'Democrat': [20, 30],\n",
        "    'Republican': [25, 25],\n",
        "    'Independent': [15, 10]\n",
        "}, index=['Male', 'Female'])\n",
        "\n",
        "# Perform Chi-Square Test\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "\n",
        "print(\"Chi-Square Statistic:\", chi2)\n",
        "print(\"p-value:\", p)\n",
        "print(\"Degrees of Freedom:\", dof)\n",
        "print(\"Expected Frequencies:\\n\", expected)\n",
        "\n",
        "# Interpretation\n",
        "if p < 0.05:\n",
        "    print(\"Significant association. Reject H‚ÇÄ.\")\n",
        "else:\n",
        "    print(\"No significant association. Fail to reject H‚ÇÄ.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìò Assumptions\n",
        "\n",
        "- Data must be **categorical**\n",
        "- Observations must be **independent**\n",
        "- Expected frequency in each cell should be ‚â• 5\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Interpretation\n",
        "\n",
        "- **Chi-Square Statistic**: Measures how far observed counts deviate from expected\n",
        "- **p-value**: If < 0.05, the association is statistically significant\n",
        "\n",
        "---\n",
        "\n",
        "For more examples and theory, check out:\n",
        "- [Scribbr‚Äôs Chi-Square Guide](https://www.scribbr.com/statistics/chi-square-tests/)\n",
        "- [Statology‚Äôs Use Cases](https://www.statology.org/when-to-use-chi-square-test/)\n"
      ],
      "metadata": {
        "id": "K3_z7reaEO4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß† Supervised Learning Algorithms\n",
        "\n",
        "| Algorithm            | Use Case Idea                                      |\n",
        "|----------------------|----------------------------------------------------|\n",
        "| **Linear Regression** | Predict house prices or student scores             |\n",
        "| **Logistic Regression** | Classify emails as spam or not spam               |\n",
        "| **K-Nearest Neighbors (KNN)** | Classify species in the Iris dataset             |\n",
        "| **Support Vector Machine (SVM)** | Detect fraudulent transactions or cancer diagnosis |\n",
        "| **Decision Trees**     | Predict loan approval or customer churn           |\n",
        "| **Random Forest**      | Feature importance in marketing campaigns         |\n",
        "| **Gradient Boosting / AdaBoost** | Improve accuracy in credit scoring models       |\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Unsupervised Learning Algorithms\n",
        "\n",
        "| Algorithm            | Use Case Idea                                      |\n",
        "|----------------------|----------------------------------------------------|\n",
        "| **K-Means Clustering** | Segment customers based on behavior               |\n",
        "| **Hierarchical Clustering** | Visualize relationships in psychological traits |\n",
        "| **DBSCAN**             | Detect anomalies in network traffic               |\n",
        "| **PCA (Dimensionality Reduction)** | Visualize high-dimensional data in 2D         |\n",
        "\n",
        "---\n",
        "\n",
        "## üéÆ Reinforcement Learning Algorithms\n",
        "\n",
        "| Algorithm            | Use Case Idea                                      |\n",
        "|----------------------|----------------------------------------------------|\n",
        "| **Q-Learning**        | Train an agent to play a simple game               |\n",
        "| **Deep Q-Networks (DQN)** | Simulate decision-making in marketing strategy     |\n",
        "| **Policy Gradient Methods** | Optimize ad placement or pricing strategies     |\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Want to Dive Deeper?\n",
        "\n",
        "You can explore full breakdowns and tutorials on these platforms:\n",
        "- [GeeksforGeeks: Machine Learning Algorithms](https://www.geeksforgeeks.org/machine-learning/machine-learning-algorithms/)\n",
        "- [Simplilearn‚Äôs ML Algorithm Guide](https://www.simplilearn.com/10-algorithms-machine-learning-engineers-need-to-know-article)\n",
        "- [Coursera‚Äôs Top 10 ML Algorithms](https://www.coursera.org/articles/machine-learning-algorithms)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "gnIBxlcDFTQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here‚Äôs a deeper dive into the **K-Nearest Neighbors (KNN)** algorithm:\n",
        "\n",
        "---\n",
        "\n",
        "## üß† What Is KNN?\n",
        "\n",
        "KNN is a **non-parametric, instance-based learning algorithm** used for classification and regression. It makes predictions by looking at the **k closest data points** in the training set and using their labels to infer the label of a new point.\n",
        "\n",
        "> It‚Äôs called a ‚Äúlazy learner‚Äù because it doesn‚Äôt build a model ‚Äî it just stores the data and makes predictions on the fly.\n",
        "\n",
        "---\n",
        "\n",
        "## üîß How KNN Works\n",
        "\n",
        "1. Choose a value for **k** (number of neighbors)\n",
        "2. Compute the **distance** between the query point and all training points (commonly Euclidean)\n",
        "3. Select the **k nearest neighbors**\n",
        "4. For classification: use **majority vote**\n",
        "   For regression: use **average value**\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Key Concepts\n",
        "\n",
        "- **Distance Metric**: Usually Euclidean, but can be Manhattan, Minkowski, etc.\n",
        "- **Feature Scaling**: Crucial! KNN is sensitive to feature magnitudes.\n",
        "- **Weighted KNN**: Closer neighbors can be given more weight (e.g., weight = 1/distance)\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Python Example: Weighted KNN Classification\n",
        "\n",
        "```python\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load and scale data\n",
        "X, y = load_iris(return_X_y=True)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train weighted KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = knn.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öñÔ∏è Choosing the Right k\n",
        "\n",
        "- **Small k** ‚Üí high variance, sensitive to noise\n",
        "- **Large k** ‚Üí high bias, smoother decision boundaries\n",
        "- Use **cross-validation** to find the optimal k\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Pros and Cons\n",
        "\n",
        "| ‚úÖ Pros                            | ‚ùå Cons                                      |\n",
        "|-----------------------------------|---------------------------------------------|\n",
        "| Simple and intuitive              | Slow with large datasets                    |\n",
        "| No training phase                 | Sensitive to irrelevant or unscaled features|\n",
        "| Works well with small data        | Doesn‚Äôt generalize well to high dimensions  |\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Further Reading\n",
        "\n",
        "- [GeeksforGeeks: KNN Algorithm](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/)\n",
        "- [IBM: What is KNN?](https://www.ibm.com/think/topics/knn)\n",
        "- [Wikipedia: k-nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
        "\n"
      ],
      "metadata": {
        "id": "bKGqK-TyFk4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here‚Äôs a comprehensive breakdown of **Regression**, **Classification**, and **Time Series** ‚Äî three pillars of supervised learning and predictive modeling.\n",
        "\n",
        "## üìâ Regression\n",
        "\n",
        "**Regression** is used to predict continuous outcomes based on input variables.\n",
        "\n",
        "### üîç Key Concepts\n",
        "- **Goal**: Estimate relationships between dependent and independent variables  \n",
        "- **Output**: Continuous values (e.g., price, temperature, score)  \n",
        "- **Common Algorithms**:\n",
        "  - Linear Regression\n",
        "  - Polynomial Regression\n",
        "  - Ridge/Lasso Regression\n",
        "  - Decision Trees & Random Forests (for regression tasks)\n",
        "\n",
        "### üß† Example\n",
        "> Predicting house prices based on square footage, number of rooms, and location.\n",
        "\n",
        "üìö Learn more: [Regression Analysis ‚Äì Investopedia](https://www.investopedia.com/terms/r/regression.asp)\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Classification\n",
        "\n",
        "**Classification** assigns data points to discrete categories or classes.\n",
        "\n",
        "### üîç Key Concepts\n",
        "- **Goal**: Predict labels or categories  \n",
        "- **Output**: Discrete values (e.g., spam vs not spam, disease type)  \n",
        "- **Types**:\n",
        "  - Binary Classification (e.g., yes/no)\n",
        "  - Multiclass Classification (e.g., cat/dog/bird)\n",
        "  - Multi-label Classification (e.g., action + comedy)\n",
        "\n",
        "### üß† Example\n",
        "> Classifying emails as spam or not spam based on keywords and sender info.\n",
        "\n",
        "üìö Learn more: [Getting Started with Classification ‚Äì GeeksforGeeks](https://www.geeksforgeeks.org/machine-learning/getting-started-with-classification/)\n",
        "\n",
        "---\n",
        "\n",
        "## ‚è≥ Time Series\n",
        "\n",
        "**Time Series** involves data collected over time, often at regular intervals.\n",
        "\n",
        "### üîç Key Concepts\n",
        "- **Goal**: Forecast future values based on historical patterns  \n",
        "- **Output**: Time-dependent predictions  \n",
        "- **Components**:\n",
        "  - **Trend**: Long-term increase/decrease\n",
        "  - **Seasonality**: Regular patterns (e.g., monthly sales)\n",
        "  - **Cyclic**: Irregular but recurring patterns\n",
        "  - **Noise**: Random fluctuations\n",
        "\n",
        "### üìà Common Models\n",
        "- ARIMA / SARIMA\n",
        "- Exponential Smoothing\n",
        "- Prophet (by Meta)\n",
        "- LSTM (Deep Learning)\n",
        "\n",
        "### üß† Example\n",
        "> Forecasting monthly sales or predicting stock prices.\n",
        "\n",
        "üìö Learn more: [Time Series Analysis ‚Äì Wikipedia](https://en.wikipedia.org/wiki/Time_series)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "2bn2WWn8VsAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here‚Äôs a clear and practical overview of **Probability in Statistics**.\n",
        "---\n",
        "\n",
        "## üé≤ What Is Probability?\n",
        "\n",
        "**Probability** is the measure of how likely an event is to occur. It ranges from **0 to 1**:\n",
        "- **0** means the event is impossible  \n",
        "- **1** means the event is certain  \n",
        "- Values in between represent varying degrees of likelihood\n",
        "\n",
        "### üìå Formula:\n",
        "\\[\n",
        "P(\\text{Event}) = \\frac{\\text{Number of Favorable Outcomes}}{\\text{Total Number of Possible Outcomes}}\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Key Terms\n",
        "\n",
        "| Term               | Meaning                                                                 |\n",
        "|--------------------|-------------------------------------------------------------------------|\n",
        "| **Experiment**      | A process that leads to an outcome (e.g., tossing a coin)               |\n",
        "| **Sample Space (S)**| All possible outcomes (e.g., {Heads, Tails})                            |\n",
        "| **Event (A)**       | A subset of the sample space (e.g., getting Heads)                      |\n",
        "| **Trial**           | A single execution of the experiment                                    |\n",
        "| **Equally Likely Events** | Events with the same chance of occurring                          |\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Types of Probability\n",
        "\n",
        "| Type                  | Description                                                                 |\n",
        "|-----------------------|------------------------------------------------------------------------------|\n",
        "| **Theoretical Probability** | Based on known possible outcomes (e.g., dice rolls)                     |\n",
        "| **Experimental Probability** | Based on actual data from experiments or observations                  |\n",
        "| **Subjective Probability** | Based on intuition or experience (e.g., weather forecasts)               |\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Example\n",
        "\n",
        "**Problem**: What‚Äôs the probability of getting a head when tossing a fair coin?\n",
        "\n",
        "- Total outcomes = 2 (Heads, Tails)  \n",
        "- Favorable outcome = 1 (Heads)  \n",
        "- So,  \n",
        "\\[\n",
        "P(\\text{Head}) = \\frac{1}{2} = 0.5\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Learn More\n",
        "\n",
        "- [GeeksforGeeks: Probability and Statistics](https://www.geeksforgeeks.org/maths/probability-and-statistics/)  \n",
        "- [Cuemath: Probability Basics](https://www.cuemath.com/data/probability/)  \n",
        "- [TutorialsPoint: Probability in Statistics](https://www.tutorialspoint.com/statistics/probability.htm)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ai3CwZL_sybR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here‚Äôs a structured breakdown of the **types of events in probability**.\n",
        "---\n",
        "\n",
        "## üéØ Types of Events in Probability\n",
        "\n",
        "| Event Type               | Description                                                                 | Example |\n",
        "|--------------------------|-----------------------------------------------------------------------------|---------|\n",
        "| **Simple Event**         | Involves only one outcome from the sample space                            | Getting a 3 when rolling a die |\n",
        "| **Compound Event**       | Involves more than one outcome                                              | Getting an even number (2, 4, 6) |\n",
        "| **Sure Event**           | Always occurs; probability = 1                                              | Getting a number < 7 on a die |\n",
        "| **Impossible Event**     | Never occurs; probability = 0                                               | Getting a 7 on a standard die |\n",
        "| **Mutually Exclusive**   | Events that cannot happen at the same time                                  | Getting heads *or* tails in one coin toss |\n",
        "| **Exhaustive Events**    | All possible outcomes are covered                                           | Tossing a coin: {Heads, Tails} |\n",
        "| **Complementary Events** | One event occurs if the other does not                                      | Getting heads vs. not getting heads |\n",
        "| **Independent Events**   | One event‚Äôs outcome does not affect the other                               | Tossing two separate coins |\n",
        "| **Dependent Events**     | One event‚Äôs outcome affects the other                                       | Drawing two cards without replacement |\n",
        "| **Conditional Events**   | Probability of one event given another has occurred                         | Probability of rain given cloudy skies |\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Quick Tip for Teaching\n",
        "\n",
        "Use **Venn diagrams** to explain mutually exclusive and overlapping events, and **tree diagrams** for dependent/independent events ‚Äî they make abstract ideas visual and intuitive.\n",
        "\n",
        "You can explore more examples and visuals on [BYJU'S guide to probability events](https://byjus.com/maths/types-of-events-in-probability/) or [GeeksforGeeks](https://www.geeksforgeeks.org/maths/types-of-events-in-probability/).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zuC6yqdHtktP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here‚Äôs a clear and engaging breakdown of **independent** vs **dependent events** in probability.\n",
        "\n",
        "---\n",
        "\n",
        "### üé≤ What Are Independent and Dependent Events?\n",
        "\n",
        "#### ‚úÖ **Independent Events**\n",
        "- **Definition**: The outcome of one event **does not affect** the outcome of another.\n",
        "- **Formula**:  \n",
        "  \\[\n",
        "  P(A \\cap B) = P(A) \\times P(B)\n",
        "  \\]\n",
        "- **Examples**:\n",
        "  - Tossing a coin and rolling a die.\n",
        "  - Choosing a random number and the weather tomorrow.\n",
        "  - Buying a lottery ticket and finding a penny on the floor.\n",
        "\n",
        "#### üîÅ **Dependent Events**\n",
        "- **Definition**: The outcome of one event **does affect** the outcome of another.\n",
        "- **Formula**:  \n",
        "  \\[\n",
        "  P(A \\cap B) = P(A) \\times P(B|A)\n",
        "  \\]\n",
        "- **Examples**:\n",
        "  - Drawing cards from a deck **without replacement**.\n",
        "  - Getting a passport and going on vacation.\n",
        "  - Parking illegally and getting a ticket.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† How to Tell the Difference\n",
        "\n",
        "| Feature                  | Independent Events                  | Dependent Events                     |\n",
        "|--------------------------|-------------------------------------|--------------------------------------|\n",
        "| Influence                | No influence between events         | One event affects the other          |\n",
        "| Probability Formula      | \\( P(A) \\times P(B) \\)              | \\( P(A) \\times P(BIA) \\)             |\n",
        "| Real-Life Analogy        | Tossing dice and flipping a coin    | Studying and passing an exam         |\n",
        "| Example                  | Rolling a die twice                 | Drawing two cards from a deck        |\n",
        "\n",
        "---\n",
        "\n",
        "### üìò Want to Dive Deeper?\n",
        "\n",
        "You can explore more examples and formulas in this [GeeksforGeeks guide](https://www.geeksforgeeks.org/maths/dependent-and-independent-events-probability/) or this [PDF textbook section](http://www.rossettimath.com/uploads/1/2/4/4/12445488/11.5_textbook_find_probabilities_of_independent_and_dependent_events.pdf).\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "7SA4-mLTwFNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add **conditional probability** to your chart and give it the spotlight it deserves üîç:\n",
        "\n",
        "---\n",
        "\n",
        "### üìå **Conditional Probability Equation**\n",
        "\n",
        "#### üîÅ **Definition**  \n",
        "The probability of event B occurring **given** that event A has already occurred.\n",
        "\n",
        "#### üßÆ **Formula**  \n",
        "\\[\n",
        "P(B|A) = \\frac{P(A \\cap B)}{P(A)}\n",
        "\\]\n",
        "\n",
        "#### üìò **Example**  \n",
        "If 40% of people like tea and 25% like both tea and coffee:\n",
        "\\[\n",
        "P(\\text{Coffee}|\\text{Tea}) = \\frac{P(\\text{Tea} \\cap \\text{Coffee})}{P(\\text{Tea})} = \\frac{0.25}{0.4} = 0.625\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### üìä Updated Chart with Conditional Probability\n",
        "\n",
        "| Event Type               | Equation                                      | Description                                  |\n",
        "|--------------------------|-----------------------------------------------|----------------------------------------------|\n",
        "| **Independent Events**   | \\( P(A ‚à© B) = P(A) √ó P(B) \\)                  | Events don‚Äôt affect each other               |\n",
        "| **Dependent Events**     | \\( P(A ‚à© B) = P(A) √ó P(B I A) \\)                | One event influences the other               |\n",
        "| **Conditional Probability** | \\( P(B I A) = \\frac{P(A ‚à© B)}{P(A)} \\)       | Probability of B given A                     |\n",
        "| **Union of Events**      | \\( P(A ‚à™ B) = P(A) + P(B) - P(A ‚à© B) \\)       | A or B or both                               |\n",
        "| **Complement Rule**      | \\( P(A') = 1 - P(A) \\)                        | Not A                                        |\n",
        "| **Mutually Exclusive**   | \\( P(A ‚à© B) = 0 \\)                            | A and B can‚Äôt happen together                |\n",
        "| **Symmetric Difference** | \\( P(A ‚ñ≥ B) = P(A ‚à™ B) - P(A ‚à© B) \\)          | A or B but not both                          |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VL2Ewl0EzR14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here‚Äôs a detailed and intuitive guide to **conditional probability**.\n",
        "---\n",
        "\n",
        "### üéØ What Is Conditional Probability?\n",
        "\n",
        "**Conditional probability** is the likelihood of an event occurring **given** that another event has already occurred.\n",
        "\n",
        "- **Notation**:  \n",
        "  \\[\n",
        "  P(A \\mid B)\n",
        "  \\]\n",
        "  This reads as ‚Äúthe probability of A given B.‚Äù\n",
        "\n",
        "- **Formula**:  \n",
        "  \\[\n",
        "  P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\n",
        "  \\]\n",
        "  Provided that \\( P(B) \\neq 0 \\)\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Why It Matters\n",
        "\n",
        "Conditional probability is essential when dealing with **dependent events**, where one outcome influences another. It‚Äôs used in:\n",
        "- Machine learning (Bayes‚Äô theorem)\n",
        "- Risk analysis\n",
        "- Medical testing\n",
        "- Game theory\n",
        "- Decision-making under uncertainty\n",
        "\n",
        "> ‚ÄúUnderstanding conditional probability is necessary to accurately calculate probability when dealing with dependent events.‚Äù ‚Äî [Britannica](https://www.britannica.com/science/conditional-probability)\n",
        "\n",
        "---\n",
        "\n",
        "### üìò Real-Life Examples\n",
        "\n",
        "#### üéÆ **Gaming Scenario**\n",
        "- Event A: Win the game\n",
        "- Event B: You go first\n",
        "- If going first increases your win rate, then:\n",
        "  \\[\n",
        "  P(\\text{Win} \\mid \\text{Go First}) > P(\\text{Win})\n",
        "  \\]\n",
        "\n",
        "#### üÉè **Card Drawing**\n",
        "- Event A: Second card is red\n",
        "- Event B: First card is red\n",
        "- Without replacement, the second draw depends on the first:\n",
        "  \\[\n",
        "  P(\\text{Red}_2 \\mid \\text{Red}_1) = \\frac{25}{51}\n",
        "  \\]\n",
        "\n",
        "#### ‚òî **Umbrella Example**\n",
        "- You carry an umbrella 50% of the time.\n",
        "- It rains 30% of the time.\n",
        "- On rainy days, you carry an umbrella 80% of the time.\n",
        "- So:\n",
        "  \\[\n",
        "  P(\\text{Rain} \\mid \\text{Umbrella}) = \\frac{2}{5} = 0.4\n",
        "  \\]\n",
        "  ‚Äî [GeeksforGeeks](https://www.geeksforgeeks.org/maths/conditional-probability/)\n",
        "\n",
        "---\n",
        "\n",
        "### üîÑ Related Concepts\n",
        "\n",
        "| Concept                     | Formula                                      | Description                                  |\n",
        "|----------------------------|-----------------------------------------------|----------------------------------------------|\n",
        "| **Joint Probability**      | \\( P(A \\cap B) \\)                            | Probability of both A and B occurring        |\n",
        "| **Marginal Probability**   | \\( P(A) \\) or \\( P(B) \\)                     | Probability of a single event                |\n",
        "| **Bayes‚Äô Theorem**         | \\( P(A \\mid B) = \\frac{P(B \\mid A)P(A)}{P(B)} \\) | Reverses conditional probability             |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "iWgJRhqI0198"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " it looks like you're blending **conditional probability** with **Bayes‚Äô Theorem**, but the equation needs a little correction. Let‚Äôs break it down clearly:\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Correct Form of **Bayes‚Äô Theorem**\n",
        "\n",
        "\\[\n",
        "P(E_1 \\mid E_2) = \\frac{P(E_2 \\mid E_1) \\cdot P(E_1)}{P(E_2)}\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### üîç What Each Term Means\n",
        "\n",
        "| Symbol               | Meaning                                                                 |\n",
        "|----------------------|-------------------------------------------------------------------------|\n",
        "| \\( P(E_1 \\mid E_2) \\) | Probability of event \\( E_1 \\) given that \\( E_2 \\) has occurred        |\n",
        "| \\( P(E_2 \\mid E_1) \\) | Probability of event \\( E_2 \\) given that \\( E_1 \\) has occurred        |\n",
        "| \\( P(E_1) \\)          | Prior probability of \\( E_1 \\)                                          |\n",
        "| \\( P(E_2) \\)          | Total probability of \\( E_2 \\)                                          |\n",
        "\n",
        "---\n",
        "\n",
        "### üìò Example: Medical Testing\n",
        "\n",
        "Let‚Äôs say:\n",
        "- \\( E_1 \\): Patient has a disease\n",
        "- \\( E_2 \\): Test result is positive\n",
        "\n",
        "You want to know:  \n",
        "**What‚Äôs the probability the patient has the disease given a positive test?**\n",
        "\n",
        "Using Bayes‚Äô Theorem:\n",
        "\\[\n",
        "P(\\text{Disease} \\mid \\text{Positive}) = \\frac{P(\\text{Positive} \\mid \\text{Disease}) \\cdot P(\\text{Disease})}{P(\\text{Positive})}\n",
        "\\]\n",
        "\n",
        "This is crucial in fields like:\n",
        "- **Machine learning** (Naive Bayes classifier)\n",
        "- **Medical diagnostics**\n",
        "- **Spam filtering**\n",
        "- **Decision-making under uncertainty**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "8YUKqKye2Cs5"
      }
    }
  ]
}